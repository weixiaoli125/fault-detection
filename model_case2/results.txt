Python 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]
Type "copyright", "credits" or "license" for more information.

IPython 7.12.0 -- An enhanced Interactive Python.

runfile('F:/wei_loss/datame/train_focal_loss.py', wdir='F:/wei_loss/datame')
D:\annocanda\lib\site-packages\tensorflow\python\framework\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
D:\annocanda\lib\site-packages\tensorflow\python\framework\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
D:\annocanda\lib\site-packages\tensorflow\python\framework\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
D:\annocanda\lib\site-packages\tensorflow\python\framework\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
D:\annocanda\lib\site-packages\tensorflow\python\framework\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
D:\annocanda\lib\site-packages\tensorflow\python\framework\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From F:\wei_loss\datame\train_focal_loss.py:21: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

D:\annocanda\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
D:\annocanda\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
D:\annocanda\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
D:\annocanda\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
D:\annocanda\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
D:\annocanda\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
>>>train_x shape: (2648862, 45, 45, 1)
>>>train_y shape: (2648862,)
>>>positive instances: 107555  negative instances: 2541307

>>>val_x shape: (1250356, 45, 45, 1)
>>>val_y shape: (1250356,)
>>>positive instances: 14673  negative instances: 1235683

WARNING:tensorflow:From F:\wei_loss\datame\train_focal_loss.py:34: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From F:\wei_loss\datame\train_focal_loss.py:35: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From F:\wei_loss\datame\train_focal_loss.py:64: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From F:\wei_loss\datame\train_focal_loss.py:70: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From F:\wei_loss\datame\train_focal_loss.py:96: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From F:\wei_loss\datame\train_focal_loss.py:137: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From F:\wei_loss\datame\focal_loss.py:75: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From F:\wei_loss\datame\train_focal_loss.py:172: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From F:\wei_loss\datame\train_focal_loss.py:178: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

>>>Epoch: 1 / 50 
  train_loss: 0.004691694351258115  train_accuracy:31.03%  train_precision: 0.05458713813872156  train_recall: 0.9795918367346848  train_f1_score: 0.10341172303612145 train_specificity: 0.28195806331151635 
  val_loss: 0.0009840462271533232  val_accuracy:93.64%  val_precision: 0.14838653750297826  val_recall: 0.9332788114222768  val_f1_score: 0.25606073331537565 val_specificity: 0.9363979273001241
>>>Epoch: 2 / 50 
  train_loss: 0.0014049382141572441  train_accuracy:89.88%  train_precision: 0.2830629148925803  train_recall: 0.9729068848496027  train_f1_score: 0.4385357969305497 train_specificity: 0.8957099634164621 
  val_loss: 0.0004867479836419831  val_accuracy:96.90%  val_precision: 0.2706520704426412  val_recall: 0.968854358345194  val_f1_score: 0.4231078302488317 val_specificity: 0.9689977121964121
>>>Epoch: 3 / 50 
  train_loss: 0.0009585013635307069  train_accuracy:93.15%  train_precision: 0.37030959068387537  train_recall: 0.9818790386313887  train_f1_score: 0.5377936432018261 train_specificity: 0.9293367546699391 
  val_loss: 0.0003339395443079797  val_accuracy:97.82%  val_precision: 0.3476797947277881  val_recall: 0.9788727594901534  val_f1_score: 0.51311088843856 val_specificity: 0.9781918178044038
>>>Epoch: 4 / 50 
  train_loss: 0.0007500632454908612  train_accuracy:94.45%  train_precision: 0.42177584808435353  train_recall: 0.9862860861884525  train_f1_score: 0.5908712394463468 train_specificity: 0.9427743283279034 
  val_loss: 0.00025683327108135017  val_accuracy:98.16%  val_precision: 0.3885797241712937  val_recall: 0.9850746268656044  val_f1_score: 0.5573163674369441 val_specificity: 0.9815947941340936
>>>Epoch: 5 / 50 
  train_loss: 0.0006222760095706181  train_accuracy:95.35%  train_precision: 0.46601252792500564  train_recall: 0.9891311422063038  train_f1_score: 0.6335422586424634 train_specificity: 0.9520309824826355 
  val_loss: 0.00020924009269663481  val_accuracy:98.58%  val_precision: 0.4514009962639959  val_recall: 0.9881414843589594  val_f1_score: 0.6197080755637565 val_specificity: 0.9857398701770592
>>>Epoch: 6 / 50 
  train_loss: 0.0005501155252857803  train_accuracy:95.74%  train_precision: 0.4878076697677804  train_recall: 0.9906094556273441  train_f1_score: 0.6537084582857519 train_specificity: 0.9559789509886051 
  val_loss: 0.00018135988924021998  val_accuracy:98.69%  val_precision: 0.47183715871829135  val_recall: 0.9905268179649022  val_f1_score: 0.6391942998531382 val_specificity: 0.986834001924441
>>>Epoch: 7 / 50 
  train_loss: 0.00048637732388923224  train_accuracy:96.38%  train_precision: 0.5290012845374399  train_recall: 0.9916972711635814  train_f1_score: 0.6899580827588696 train_specificity: 0.9626306463563824 
  val_loss: 0.0001586138707226737  val_accuracy:98.91%  val_precision: 0.5193056398899697  val_recall: 0.9908675799086082  val_f1_score: 0.6814623852998334 val_specificity: 0.9891088572069042
>>>Epoch: 8 / 50 
  train_loss: 0.00043252721606031367  train_accuracy:96.72%  train_precision: 0.553283295260884  train_recall: 0.9931012040351356  train_f1_score: 0.710646422789324 train_specificity: 0.9660647060744724 
  val_loss: 0.00013872085982564308  val_accuracy:99.05%  val_precision: 0.5522869614727443  val_recall: 0.9916172561847617  val_f1_score: 0.7094446336035461 val_specificity: 0.9904546716269457
>>>Epoch: 9 / 50 
  train_loss: 0.00038275581380137945  train_accuracy:97.07%  train_precision: 0.5811875642371181  train_recall: 0.9936683557249686  train_f1_score: 0.7334101915437375 train_specificity: 0.9696947279490432 
  val_loss: 0.00012130839588652498  val_accuracy:99.14%  val_precision: 0.5791148049468892  val_recall: 0.9925032372383975  val_f1_score: 0.731441486224662 val_specificity: 0.9914346964391345
>>>Epoch: 10 / 50 
  train_loss: 0.0003511243855361325  train_accuracy:97.28%  train_precision: 0.5997780094850459  train_recall: 0.9947654688298917  train_f1_score: 0.748350183659569 train_specificity: 0.9719065819281177 
  val_loss: 0.00011672602710836885  val_accuracy:99.23%  val_precision: 0.605927095889247  val_recall: 0.9935255230695158  val_f1_score: 0.7527625731118909 val_specificity: 0.9923273201945799
>>>Epoch: 11 / 50 
  train_loss: 0.00032581287073954316  train_accuracy:97.55%  train_precision: 0.6247088016347943  train_recall: 0.9948119566733207  train_f1_score: 0.76747121854845 train_specificity: 0.9747067158749412 
  val_loss: 0.00010399633758713197  val_accuracy:99.26%  val_precision: 0.6125199429003018  val_recall: 0.9942751993456693  val_f1_score: 0.7580473352690072 val_specificity: 0.9925312559936481
>>>Epoch: 12 / 50 
  train_loss: 0.000300230472680768  train_accuracy:97.77%  train_precision: 0.6466568792706539  train_recall: 0.9951559667146949  train_f1_score: 0.7839193766876864 train_specificity: 0.9769862515626798 
  val_loss: 9.170753396718154e-05  val_accuracy:99.35%  val_precision: 0.6434932110738563  val_recall: 0.994820418455599  val_f1_score: 0.7814867356098961 val_specificity: 0.9934554412418064
>>>Epoch: 13 / 50 
  train_loss: 0.00028504089985261  train_accuracy:97.93%  train_precision: 0.6635555720819504  train_recall: 0.9954906791873832  train_f1_score: 0.7963170239851708 train_specificity: 0.9786377639537447 
  val_loss: 9.498662027482845e-05  val_accuracy:99.39%  val_precision: 0.6597784309292037  val_recall: 0.9944115041231517  val_f1_score: 0.7932477977154819 val_specificity: 0.9939110597135342
>>>Epoch: 14 / 50 
  train_loss: 0.00025290868695584533  train_accuracy:98.18%  train_precision: 0.6919226819769914  train_recall: 0.9961229138580169  train_f1_score: 0.8166130576421174 train_specificity: 0.981228950299983 
  val_loss: 7.674367608576348e-05  val_accuracy:99.49%  val_precision: 0.6964524127407641  val_recall: 0.99543378995427  val_f1_score: 0.8195258797231707 val_specificity: 0.9948481932663953
>>>Epoch: 15 / 50 
  train_loss: 0.00024246946343907164  train_accuracy:98.21%  train_precision: 0.6946752926838711  train_recall: 0.9963460555064757  train_f1_score: 0.8186023057068716 train_specificity: 0.9814662297786135 
  val_loss: 8.117943013506037e-05  val_accuracy:99.41%  val_precision: 0.6663321625689611  val_recall: 0.9955700947317525  val_f1_score: 0.7983386157617922 val_specificity: 0.9940801969437137
>>>Epoch: 16 / 50 
  train_loss: 0.00022512593726808068  train_accuracy:98.44%  train_precision: 0.7233758168169742  train_recall: 0.9963088652317326  train_f1_score: 0.8381835882974885 train_specificity: 0.9838752264090875 
  val_loss: 6.968289148726963e-05  val_accuracy:99.55%  val_precision: 0.7243310208126499  val_recall: 0.9961834662304234  val_f1_score: 0.8387800184491118 val_specificity: 0.9954980363086642
>>>Epoch: 17 / 50 
  train_loss: 0.00020899945792022552  train_accuracy:98.51%  train_precision: 0.7323956176142877  train_recall: 0.9963181628004184  train_f1_score: 0.8442103765579865 train_specificity: 0.9845929673195718 
  val_loss: 7.57132056799022e-05  val_accuracy:99.52%  val_precision: 0.7092904667087218  val_recall: 0.9953656375655288  val_f1_score: 0.8283235022363576 val_specificity: 0.9951557155030853
>>>Epoch: 18 / 50 
  train_loss: 0.000201174785119723  train_accuracy:98.51%  train_precision: 0.7326126470869557  train_recall: 0.9968109339407651  train_f1_score: 0.8445314433648783 train_specificity: 0.9846024112789203 
  val_loss: 6.264826616878557e-05  val_accuracy:99.62%  val_precision: 0.7572634522761015  val_recall: 0.9965242281741296  val_f1_score: 0.8605732441681924 val_specificity: 0.9962069559911394
>>>Epoch: 19 / 50 
  train_loss: 0.00019177100243252015  train_accuracy:98.65%  train_precision: 0.7519160782278766  train_recall: 0.9969782901771094  train_f1_score: 0.857277625387235 train_specificity: 0.986078423425426 
  val_loss: 5.6759352347259743e-05  val_accuracy:99.66%  val_precision: 0.774231115345891  val_recall: 0.9967968377290944  val_f1_score: 0.871529018695069 val_specificity: 0.9965484675276742
>>>Epoch: 20 / 50 
  train_loss: 0.0001786834747243132  train_accuracy:98.76%  train_precision: 0.767736298990993  train_recall: 0.9967830412347078  train_f1_score: 0.8673937486487832 train_specificity: 0.9872372759371454 
  val_loss: 5.7245645176917525e-05  val_accuracy:99.65%  val_precision: 0.7738385014286816  val_recall: 0.996660532951612  val_f1_score: 0.8712281428458675 val_specificity: 0.9965411841062789
>>>Epoch: 21 / 50 
  train_loss: 0.00016796016617478247  train_accuracy:98.85%  train_precision: 0.7803492178974116  train_recall: 0.9972479196689973  train_f1_score: 0.8755658042869313 train_specificity: 0.9881198926379218 
  val_loss: 5.463885459846676e-05  val_accuracy:99.71%  val_precision: 0.8058771639651116  val_recall: 0.9961834662304234  val_f1_score: 0.8909816824776957 val_specificity: 0.9971505636963518
>>>Epoch: 22 / 50 
  train_loss: 0.00016129481186655145  train_accuracy:98.86%  train_precision: 0.7819780155698692  train_recall: 0.9974245734740272  train_f1_score: 0.8766583717590317 train_specificity: 0.9882304656619602 
  val_loss: 5.468815097299585e-05  val_accuracy:99.65%  val_precision: 0.7723912125052401  val_recall: 0.9967968377290944  val_f1_score: 0.87036210489643 val_specificity: 0.9965120504206978
>>>Epoch: 23 / 50 
  train_loss: 0.00015433429755607643  train_accuracy:98.98%  train_precision: 0.8010840998685881  train_recall: 0.9975733345729998  train_f1_score: 0.8885962618925495 train_specificity: 0.9895164181265778 
  val_loss: 5.378809872351575e-05  val_accuracy:99.70%  val_precision: 0.7988311120821062  val_recall: 0.9967286853403532  val_f1_score: 0.8868742604441356 val_specificity: 0.9970194621112365
>>>Epoch: 24 / 50 
  train_loss: 0.00015023020124629977  train_accuracy:99.00%  train_precision: 0.8030357463624873  train_recall: 0.9975547394356282  train_f1_score: 0.8897882340194141 train_specificity: 0.9896446985743946 
  val_loss: 4.995012982176626e-05  val_accuracy:99.71%  val_precision: 0.8038138154640433  val_recall: 0.9968649901178357  val_f1_score: 0.8899908726422915 val_specificity: 0.9971109095131997
>>>Epoch: 25 / 50 
  train_loss: 0.00014137106502779597  train_accuracy:99.06%  train_precision: 0.8131621625717992  train_recall: 0.9976291199851146  train_f1_score: 0.8959997322918406 train_specificity: 0.9902986927592766 
  val_loss: 4.5435551969661175e-05  val_accuracy:99.77%  val_precision: 0.8387891991056103  val_recall: 0.9971375996728006  val_f1_score: 0.9111346364447512 val_specificity: 0.9977243354484922
>>>Epoch: 26 / 50 
  train_loss: 0.0001360917956973903  train_accuracy:99.16%  train_precision: 0.8299763308117075  train_recall: 0.9976384175538003  train_f1_score: 0.9061168646899609 train_specificity: 0.9913505137317132 
  val_loss: 4.298008421714767e-05  val_accuracy:99.75%  val_precision: 0.8255695916985774  val_recall: 0.9976828187827304  val_f1_score: 0.9035025454078097 val_specificity: 0.9974969308471502
>>>Epoch: 27 / 50 
  train_loss: 0.00012723911242635893  train_accuracy:99.17%  train_precision: 0.831571851415636  train_recall: 0.9978243689275161  train_f1_score: 0.9071437320970054 train_specificity: 0.9914465273184228 
  val_loss: 3.892658344966827e-05  val_accuracy:99.76%  val_precision: 0.8331152204835941  val_recall: 0.997887275948954  val_f1_score: 0.908087322748845 val_specificity: 0.9976264138941776
>>>Epoch: 28 / 50 
  train_loss: 0.0001246297301696731  train_accuracy:99.17%  train_precision: 0.8311284950817068  train_recall: 0.997694202965915  train_f1_score: 0.9068261039133259 train_specificity: 0.9914205564302144 
  val_loss: 4.0924684947548634e-05  val_accuracy:99.79%  val_precision: 0.8470526985595622  val_recall: 0.9979554283376952  val_f1_score: 0.9163329156484689 val_specificity: 0.9978602926478709
>>>Epoch: 29 / 50 
  train_loss: 0.00011359274957528835  train_accuracy:99.23%  train_precision: 0.842234913860727  train_recall: 0.9981683789688903  train_f1_score: 0.9135956901381151 train_specificity: 0.9920867490625883 
  val_loss: 3.7301571701979154e-05  val_accuracy:99.80%  val_precision: 0.8555575024822817  val_recall: 0.9982961902814013  val_f1_score: 0.9214317161790087 val_specificity: 0.9979986776543814
>>>Epoch: 30 / 50 
  train_loss: 0.00011552364934894859  train_accuracy:99.24%  train_precision: 0.8431072261621402  train_recall: 0.9981125935567756  train_f1_score: 0.9140852500953173 train_specificity: 0.9921390843373111 
  val_loss: 3.2136081561748876e-05  val_accuracy:99.81%  val_precision: 0.8603325694811176  val_recall: 0.997887275948954  val_f1_score: 0.9240186792956891 val_specificity: 0.998076367482598
>>>Epoch: 31 / 50 
  train_loss: 0.00011533912183225826  train_accuracy:99.27%  train_precision: 0.848635785046205  train_recall: 0.9979824275951745  train_f1_score: 0.9172698445711575 train_specificity: 0.9924664749280583 
  val_loss: 3.40949262582494e-05  val_accuracy:99.82%  val_precision: 0.8678876244665203  val_recall: 0.9979554283376952  val_f1_score: 0.9283880166207731 val_specificity: 0.9981961393010983
>>>Epoch: 32 / 50 
  train_loss: 0.00010180695822989063  train_accuracy:99.34%  train_precision: 0.8608850437390182  train_recall: 0.9982520570870624  train_f1_score: 0.9244936965475656 train_specificity: 0.9931728043876632 
  val_loss: 4.316560552838335e-05  val_accuracy:99.76%  val_precision: 0.83389366915489  val_recall: 0.9973420568390242  val_f1_score: 0.9083235051832764 val_specificity: 0.9976409807369682
>>>Epoch: 33 / 50 
  train_loss: 0.00010785023884931644  train_accuracy:99.33%  train_precision: 0.8602623586636787  train_recall: 0.9981218911254613  train_f1_score: 0.9240787441335957 train_specificity: 0.9931381765367188 
  val_loss: 3.634120244346332e-05  val_accuracy:99.83%  val_precision: 0.8778104202889335  val_recall: 0.9978191235602127  val_f1_score: 0.9339755034570779 val_specificity: 0.9983507096884873
>>>Epoch: 34 / 50 
  train_loss: 0.0001031268396257135  train_accuracy:99.35%  train_precision: 0.8638346155084103  train_recall: 0.9980661057133466  train_f1_score: 0.9261117312979691 train_specificity: 0.9933416151610172 
  val_loss: 3.562975281483142e-05  val_accuracy:99.83%  val_precision: 0.8760469011724769  val_recall: 0.9980235807264364  val_f1_score: 0.9330657231632137 val_specificity: 0.9983231945409939
>>>Epoch: 35 / 50 
  train_loss: 9.364443346177732e-05  train_accuracy:99.45%  train_precision: 0.8811208325809609  train_recall: 0.9981311886941472  train_f1_score: 0.935983224796512 train_specificity: 0.9943005705331938 
  val_loss: 2.4601649627803377e-05  val_accuracy:99.87%  val_precision: 0.9041712945821977  val_recall: 0.9986369522251074  val_f1_score: 0.9490592306938909 val_specificity: 0.9987432051747892
>>>Epoch: 36 / 50 
  train_loss: 9.04322097808061e-05  train_accuracy:99.46%  train_precision: 0.8832132398907571  train_recall: 0.998317140067863  train_f1_score: 0.937244409807065 train_specificity: 0.9944131110487632 
  val_loss: 4.138094233428325e-05  val_accuracy:99.79%  val_precision: 0.8493325594892136  val_recall: 0.9973420568390242  val_f1_score: 0.9174058860968916 val_specificity: 0.9978991375619791
>>>Epoch: 37 / 50 
  train_loss: 8.963356735520013e-05  train_accuracy:99.47%  train_precision: 0.8863246170100296  train_recall: 0.9983729254799777  train_f1_score: 0.9390180444238646 train_specificity: 0.9945807413271986 
  val_loss: 2.3582530720241492e-05  val_accuracy:99.88%  val_precision: 0.9117610454262034  val_recall: 0.9985687998363661  val_f1_score: 0.9531925961896475 val_specificity: 0.9988524564957186
>>>Epoch: 38 / 50 
  train_loss: 9.141391126263711e-05  train_accuracy:99.44%  train_precision: 0.8790337104405698  train_recall: 0.9983822230486634  train_f1_score: 0.9349144362121682 train_specificity: 0.9941852755294811 
  val_loss: 2.4818113372834407e-05  val_accuracy:99.88%  val_precision: 0.9099378881987013  val_recall: 0.9984324950588838  val_f1_score: 0.9521333631639647 val_specificity: 0.9988265598863131
>>>Epoch: 39 / 50 
  train_loss: 8.144186137121835e-05  train_accuracy:99.52%  train_precision: 0.8958665276329435  train_recall: 0.9984844963042071  train_f1_score: 0.9443960774155422 train_specificity: 0.9950879606438731 
  val_loss: 3.356702609332801e-05  val_accuracy:99.85%  val_precision: 0.8884911727233581  val_recall: 0.9980917331151776  val_f1_score: 0.9401078438975702 val_specificity: 0.9985125634972716
>>>Epoch: 40 / 50 
  train_loss: 8.78696729242095e-05  train_accuracy:99.48%  train_precision: 0.8880995112107178  train_recall: 0.9983822230486634  train_f1_score: 0.9400173324965444 train_specificity: 0.9946759679172957 
  val_loss: 2.476597592622023e-05  val_accuracy:99.87%  val_precision: 0.9004855860839079  val_recall: 0.9984324950588838  val_f1_score: 0.9469329708670501 val_specificity: 0.9986897934178904
>>>Epoch: 41 / 50 
  train_loss: 8.921576925697072e-05  train_accuracy:99.47%  train_precision: 0.8862953547492416  train_recall: 0.9983729254799777  train_f1_score: 0.9390016216362441 train_specificity: 0.9945791673339739 
  val_loss: 2.9113995254867266e-05  val_accuracy:99.86%  val_precision: 0.8973118608780296  val_recall: 0.9987051046138486  val_f1_score: 0.9452973804844678 val_specificity: 0.998642855813343
>>>Epoch: 42 / 50 
  train_loss: 6.961149999572266e-05  train_accuracy:99.58%  train_precision: 0.9068255870882708  train_recall: 0.9988192087768956  train_f1_score: 0.9506019347195656 train_specificity: 0.9956565656963126 
  val_loss: 2.6516130507552053e-05  val_accuracy:99.86%  val_precision: 0.8932666504024827  val_recall: 0.9981598855039189  val_f1_score: 0.942804724468486 val_specificity: 0.9985837791731367
>>>Epoch: 43 / 50 
  train_loss: 7.272740646683324e-05  train_accuracy:99.56%  train_precision: 0.9025855621938129  train_recall: 0.9986890428152945  train_f1_score: 0.9482084369267861 train_specificity: 0.995438174136379 
  val_loss: 2.82960086036747e-05  val_accuracy:99.84%  val_precision: 0.8812560153993695  val_recall: 0.9984324950588838  val_f1_score: 0.9361919667830922 val_specificity: 0.9984025029072983
>>>Epoch: 44 / 50 
  train_loss: 7.087673855834444e-05  train_accuracy:99.57%  train_precision: 0.9061490311205518  train_recall: 0.9986890428152945  train_f1_score: 0.9501711672455612 train_specificity: 0.9956223313436744 
  val_loss: 2.2852457860878857e-05  val_accuracy:99.89%  val_precision: 0.9174857572152434  val_recall: 0.9987732570025899  val_f1_score: 0.9564054031424218 val_specificity: 0.9989333834001107
>>>Epoch: 45 / 50 
  train_loss: 7.288209519810119e-05  train_accuracy:99.55%  train_precision: 0.9016620498614882  train_recall: 0.9986983403839803  train_f1_score: 0.9477027588369373 train_specificity: 0.9953901673430243 
  val_loss: 2.2977540589642058e-05  val_accuracy:99.87%  val_precision: 0.9033470997965294  val_recall: 0.9987732570025899  val_f1_score: 0.9486664935457335 val_specificity: 0.9987310661391304
>>>Epoch: 46 / 50 
  train_loss: 6.712277164799019e-05  train_accuracy:99.62%  train_precision: 0.9147591797806311  train_recall: 0.9987634233647807  train_f1_score: 0.9549173947282349 train_specificity: 0.9960610819550724 
  val_loss: 1.686933257589995e-05  val_accuracy:99.92%  val_precision: 0.938949391415699  val_recall: 0.9989095617800723  val_f1_score: 0.9680018487227506 val_specificity: 0.9992287666011421
>>>Epoch: 47 / 50 
  train_loss: 6.791580436681075e-05  train_accuracy:99.62%  train_precision: 0.9163538325028929  train_recall: 0.9985960671284366  train_f1_score: 0.9557089017668561 train_specificity: 0.9961421426061468 
  val_loss: 2.2142141304234222e-05  val_accuracy:99.90%  val_precision: 0.9192647889090446  val_recall: 0.9987051046138486  val_f1_score: 0.9573397786867884 val_specificity: 0.9989584707404723
>>>Epoch: 48 / 50 
  train_loss: 6.372812379978253e-05  train_accuracy:99.64%  train_precision: 0.9190130301241334  train_recall: 0.9987169355213519  train_f1_score: 0.9572086718290703 train_specificity: 0.9962751450336378 
  val_loss: 2.1533401461821447e-05  val_accuracy:99.89%  val_precision: 0.9144354989701732  val_recall: 0.9985687998363661  val_f1_score: 0.9546520714321011 val_specificity: 0.998890492140783
>>>Epoch: 49 / 50 
  train_loss: 6.461849989431141e-05  train_accuracy:99.62%  train_precision: 0.91445425217694  train_recall: 0.9988471014829529  train_f1_score: 0.954789455410241 train_specificity: 0.9960453420228249 
  val_loss: 2.0681799974707416e-05  val_accuracy:99.92%  val_precision: 0.9399012250656827  val_recall: 0.9987051046138486  val_f1_score: 0.9684113132725346 val_specificity: 0.9992417149058448
>>>Epoch: 50 / 50 
  train_loss: 6.465787012343626e-05  train_accuracy:99.64%  train_precision: 0.9198191564057256  train_recall: 0.9987634233647807  train_f1_score: 0.9576671223183344 train_specificity: 0.9963152818608688 
  val_loss: 2.6980822781283137e-05  val_accuracy:99.88%  val_precision: 0.9072835377182641  val_recall: 0.9983643426701425  val_f1_score: 0.950647327448126 val_specificity: 0.9987885242412489
Model saved in file: ./results/xin_49/log/521model.ckpt
F:\wei_loss\datame\train_focal_loss.py:267: UserWarning: The following kwargs were not used by contour: 'aspect'
  h3 = plt.contourf(A[13200,:,:,0],cmap = plt.cm.GnBu,norm = norm,aspect='auto')#A[13200,:,:,0]