runfile('F:/wei_loss/datame/train_focal_loss.py', wdir='F:/wei_loss/datame')
D:\annocanda\lib\site-packages\tensorflow\python\framework\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
D:\annocanda\lib\site-packages\tensorflow\python\framework\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
D:\annocanda\lib\site-packages\tensorflow\python\framework\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
D:\annocanda\lib\site-packages\tensorflow\python\framework\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
D:\annocanda\lib\site-packages\tensorflow\python\framework\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
D:\annocanda\lib\site-packages\tensorflow\python\framework\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From F:\wei_loss\datame\train_focal_loss.py:21: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.

D:\annocanda\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
D:\annocanda\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
D:\annocanda\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
D:\annocanda\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
D:\annocanda\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
D:\annocanda\lib\site-packages\tensorboard\compat\tensorflow_stub\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
>>>train_x shape: (539930, 45, 45, 1)
>>>train_y shape: (539930,)
>>>positive instances: 107555  negative instances: 432375

>>>val_x shape: (1250356, 45, 45, 1)
>>>val_y shape: (1250356,)
>>>positive instances: 14673  negative instances: 1235683

WARNING:tensorflow:From F:\wei_loss\datame\train_focal_loss.py:34: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.

WARNING:tensorflow:From F:\wei_loss\datame\train_focal_loss.py:35: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.

WARNING:tensorflow:From F:\wei_loss\datame\train_focal_loss.py:64: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.

WARNING:tensorflow:From F:\wei_loss\datame\train_focal_loss.py:70: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.

WARNING:tensorflow:
The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
  * https://github.com/tensorflow/io (for I/O related ops)
If you depend on functionality not listed there, please file an issue.

WARNING:tensorflow:From F:\wei_loss\datame\train_focal_loss.py:96: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.

WARNING:tensorflow:From F:\wei_loss\datame\train_focal_loss.py:137: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From F:\wei_loss\datame\focal_loss.py:75: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
WARNING:tensorflow:From F:\wei_loss\datame\train_focal_loss.py:172: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.

WARNING:tensorflow:From F:\wei_loss\datame\train_focal_loss.py:178: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.

>>>Epoch: 1 / 50 
  train_loss: 0.03966891944699303  train_accuracy:24.70%  train_precision: 0.20563344228724412  train_recall: 0.9709729905629587  train_f1_score: 0.3393904923059784 train_specificity: 0.06695114194853989 
  val_loss: 0.007608519380951536  val_accuracy:96.11%  val_precision: 0.11155778894472108  val_recall: 0.3328562666121221  val_f1_score: 0.1671086168035886 val_specificity: 0.9685226712676303
>>>Epoch: 2 / 50 
  train_loss: 0.016368565283043153  train_accuracy:86.32%  train_precision: 0.6032152685417256  train_recall: 0.915066710055312  train_f1_score: 0.7271142233883435 train_specificity: 0.8502711766406457 
  val_loss: 0.0022059610108208674  val_accuracy:99.14%  val_precision: 0.5929921710902906  val_recall: 0.8465889729434439  val_f1_score: 0.6974537487083688 val_specificity: 0.9931001721315249
>>>Epoch: 3 / 50 
  train_loss: 0.008682256704152349  train_accuracy:94.08%  train_precision: 0.7901344465590214  train_recall: 0.9573148621635353  train_f1_score: 0.8657274858730019 train_specificity: 0.9367493495229814 
  val_loss: 0.0012781094640437207  val_accuracy:99.48%  val_precision: 0.7191367990528081  val_recall: 0.9107203707489326  val_f1_score: 0.8036686207668211 val_specificity: 0.9957764248597731
>>>Epoch: 4 / 50 
  train_loss: 0.0065541267564680206  train_accuracy:95.56%  train_precision: 0.8351430679412264  train_recall: 0.9682395053693369  train_f1_score: 0.8967797765542677 train_specificity: 0.9524556230124291 
  val_loss: 0.0008597223735117591  val_accuracy:99.62%  val_precision: 0.7770786516853496  val_recall: 0.9426838410685652  val_f1_score: 0.8519077382413807 val_specificity: 0.9967888204337189
>>>Epoch: 5 / 50 
  train_loss: 0.0055567903562084775  train_accuracy:96.17%  train_precision: 0.8540670051423239  train_recall: 0.9743851982706432  train_f1_score: 0.9102674339898276 train_specificity: 0.95858456201214 
  val_loss: 0.0006662822403824114  val_accuracy:99.67%  val_precision: 0.8038889526212686  val_recall: 0.9551557282082086  val_f1_score: 0.8730183444128529 val_specificity: 0.9972331091388318
>>>Epoch: 6 / 50 
  train_loss: 0.004787830153986843  train_accuracy:96.67%  train_precision: 0.8706030358709435  train_recall: 0.9779926549207291  train_f1_score: 0.9211785770291886 train_specificity: 0.9638415727088732 
  val_loss: 0.0005264631816140653  val_accuracy:99.73%  val_precision: 0.8335393489904742  val_recall: 0.9651059769644268  val_f1_score: 0.8945107695108305 val_specificity: 0.9977113871437894
>>>Epoch: 7 / 50 
  train_loss: 0.004344289358883119  train_accuracy:97.01%  train_precision: 0.8822058282311144  train_recall: 0.9806424619961789  train_f1_score: 0.9288233501977433 train_specificity: 0.9674287366290814 
  val_loss: 0.00042249324827719467  val_accuracy:99.77%  val_precision: 0.8510650993495524  val_recall: 0.9720575206160313  val_f1_score: 0.9075464489803831 val_specificity: 0.9979800644663713
>>>Epoch: 8 / 50 
  train_loss: 0.003810427132555123  train_accuracy:97.32%  train_precision: 0.8931053996300506  train_recall: 0.9831342104039702  train_f1_score: 0.9359598493807634 train_specificity: 0.9707291124602464 
  val_loss: 0.00038164677816119675  val_accuracy:99.79%  val_precision: 0.8669010243044507  val_recall: 0.9747836161656801  val_f1_score: 0.9176825351105364 val_specificity: 0.9982228451795477
>>>Epoch: 9 / 50 
  train_loss: 0.0035856327304641996  train_accuracy:97.45%  train_precision: 0.8969531243385943  train_recall: 0.9850681046906142  train_f1_score: 0.9389478716718104 train_specificity: 0.9718485111303823 
  val_loss: 0.0003435056657671437  val_accuracy:99.80%  val_precision: 0.8694362017803627  val_recall: 0.978463845157706  val_f1_score: 0.9207336620425651 val_specificity: 0.9982552159413046
>>>Epoch: 10 / 50 
  train_loss: 0.0032627956606589657  train_accuracy:97.71%  train_precision: 0.9066941280028636  train_recall: 0.9864255497187393  train_f1_score: 0.9448808373762658 train_specificity: 0.9747487713211889 
  val_loss: 0.00029064096700136255  val_accuracy:99.84%  val_precision: 0.893220128904258  val_recall: 0.9822803789272144  val_f1_score: 0.9356356903706178 val_specificity: 0.9986056294373226
>>>Epoch: 11 / 50 
  train_loss: 0.0030086970217594266  train_accuracy:97.88%  train_precision: 0.9131257200832208  train_recall: 0.9874203895681187  train_f1_score: 0.9488209196252971 train_specificity: 0.9766313963573264 
  val_loss: 0.00024460019528361885  val_accuracy:99.86%  val_precision: 0.9028950165696927  val_recall: 0.9841204934232274  val_f1_score: 0.9417596029705054 val_specificity: 0.9987432051747892
>>>Epoch: 12 / 50 
  train_loss: 0.0027729901530751315  train_accuracy:98.04%  train_precision: 0.919201874281359  train_recall: 0.9885639905164707  train_f1_score: 0.9526220058977567 train_specificity: 0.9783845041919608 
  val_loss: 0.00021882227549990278  val_accuracy:99.87%  val_precision: 0.9139662687132263  val_recall: 0.9860969126967228  val_f1_score: 0.948662469996331 val_specificity: 0.9988977755621782
>>>Epoch: 13 / 50 
  train_loss: 0.0026339794538850023  train_accuracy:98.15%  train_precision: 0.9230535701894306  train_recall: 0.9894193668355633  train_f1_score: 0.9550849696365188 train_specificity: 0.9794830875975693 
  val_loss: 0.00021930574479328059  val_accuracy:99.88%  val_precision: 0.916867164746048  val_recall: 0.9869147413616174  val_f1_score: 0.9506022905039951 val_specificity: 0.9989374297453304
>>>Epoch: 14 / 50 
  train_loss: 0.0023866408669130862  train_accuracy:98.29%  train_precision: 0.9285894898377269  train_recall: 0.990181767467798  train_f1_score: 0.9583970765869521 train_specificity: 0.9810581092801365 
  val_loss: 0.0001949717541631527  val_accuracy:99.88%  val_precision: 0.9187785098833681  val_recall: 0.9883459415251831  val_f1_score: 0.9522933967491827 val_specificity: 0.998962517085692
>>>Epoch: 15 / 50 
  train_loss: 0.0023123568158006217  train_accuracy:98.31%  train_precision: 0.929070162745483  train_recall: 0.9909534656687183  train_f1_score: 0.9590145491104516 train_specificity: 0.9811806880601307 
  val_loss: 0.0001791035720302779  val_accuracy:99.89%  val_precision: 0.9250525779108454  val_recall: 0.989231922578819  val_f1_score: 0.9560663939149372 val_specificity: 0.9990482996043476
>>>Epoch: 16 / 50 
  train_loss: 0.002229656611448466  train_accuracy:98.41%  train_precision: 0.9328567803802426  train_recall: 0.9912974757100925  train_f1_score: 0.9611896428598697 train_specificity: 0.9822515177797029 
  val_loss: 0.00015611818751058804  val_accuracy:99.91%  val_precision: 0.9351017254699372  val_recall: 0.9898452940774899  val_f1_score: 0.9616950830957718 val_specificity: 0.9991842568037265
>>>Epoch: 17 / 50 
  train_loss: 0.0020612532705577397  train_accuracy:98.49%  train_precision: 0.9361297058281561  train_recall: 0.9920598763423272  train_f1_score: 0.9632836193184099 train_specificity: 0.9831627638045656 
  val_loss: 0.00015382642783748473  val_accuracy:99.91%  val_precision: 0.9366265215430581  val_recall: 0.9911401894635731  val_f1_score: 0.9631125822817929 val_specificity: 0.9992036792607806
>>>Epoch: 18 / 50 
  train_loss: 0.0020104692830813804  train_accuracy:98.56%  train_precision: 0.9387916630023662  train_recall: 0.9925154572079309  train_f1_score: 0.9649063335342288 train_specificity: 0.9839028620988702 
  val_loss: 0.00014831337005582213  val_accuracy:99.91%  val_precision: 0.9358743239762467  val_recall: 0.9906631227423845  val_f1_score: 0.9624896535311303 val_specificity: 0.9991939680322535
>>>Epoch: 19 / 50 
  train_loss: 0.0018484779664946697  train_accuracy:98.65%  train_precision: 0.9421639980591863  train_recall: 0.9929710380735345  train_f1_score: 0.9669005472347073 train_specificity: 0.98483723619543 
  val_loss: 0.00014170975111408739  val_accuracy:99.91%  val_precision: 0.9385964912280096  val_recall: 0.9917535609622441  val_f1_score: 0.9644431184319519 val_specificity: 0.999229575870186
>>>Epoch: 20 / 50 
  train_loss: 0.001817145906031189  train_accuracy:98.67%  train_precision: 0.9429358381298691  train_recall: 0.9930919064664497  train_f1_score: 0.9673641829709445 train_specificity: 0.9850500144550426 
  val_loss: 0.00012389771591216056  val_accuracy:99.92%  val_precision: 0.9412981639513226  val_recall: 0.9922987800721739  val_f1_score: 0.966125874554197 val_specificity: 0.9992651837081186
>>>Epoch: 21 / 50 
  train_loss: 0.0017174698961469703  train_accuracy:98.74%  train_precision: 0.9455190285405914  train_recall: 0.9939751754915996  train_f1_score: 0.9691417895303093 train_specificity: 0.985753107834632 
  val_loss: 0.0001217259273190487  val_accuracy:99.92%  val_precision: 0.9442967382140623  val_recall: 0.9924350848496564  val_f1_score: 0.967767660828084 val_specificity: 0.9993048378912707
>>>Epoch: 22 / 50 
  train_loss: 0.0016869741737415183  train_accuracy:98.82%  train_precision: 0.948785962048553  train_recall: 0.9943749709450885  train_f1_score: 0.9710456781427089 train_specificity: 0.9866481642093068 
  val_loss: 0.00012134674784262935  val_accuracy:99.93%  val_precision: 0.9505512427424522  val_recall: 0.9930484563483273  val_f1_score: 0.9713352438172198 val_specificity: 0.9993865740647068
>>>Epoch: 23 / 50 
  train_loss: 0.0015084727901819004  train_accuracy:98.89%  train_precision: 0.9523457537759961  train_recall: 0.9942541025521733  train_f1_score: 0.9728488052388636 train_specificity: 0.9876241688349211 
  val_loss: 0.00010873080096806341  val_accuracy:99.94%  val_precision: 0.9545484314623777  val_recall: 0.9933210659032922  val_f1_score: 0.9735488606316539 val_specificity: 0.9994383672835178
>>>Epoch: 24 / 50 
  train_loss: 0.0015150721340529373  train_accuracy:98.95%  train_precision: 0.9548696979706902  train_recall: 0.9944121612198318  train_f1_score: 0.9742398566716822 train_specificity: 0.9883087597571529 
  val_loss: 0.00010409178135373531  val_accuracy:99.94%  val_precision: 0.9538018583954355  val_recall: 0.9933892182920334  val_f1_score: 0.9731931225180017 val_specificity: 0.9994286560549906
>>>Epoch: 25 / 50 
  train_loss: 0.0013946963757809148  train_accuracy:98.99%  train_precision: 0.9562408406905587  train_recall: 0.9949421226349217  train_f1_score: 0.9752076654848868 train_specificity: 0.9886741832899659 
  val_loss: 9.757028231498456e-05  val_accuracy:99.94%  val_precision: 0.9570978745735399  val_recall: 0.9943433517344105  val_f1_score: 0.9753651764897883 val_specificity: 0.9994707380452746
>>>Epoch: 26 / 50 
  train_loss: 0.0013393008932628759  train_accuracy:99.02%  train_precision: 0.9575772218046372  train_recall: 0.9949793129096648  train_f1_score: 0.9759200399906195 train_specificity: 0.9890349812084395 
  val_loss: 9.596152291606235e-05  val_accuracy:99.94%  val_precision: 0.9557638115210069  val_recall: 0.9939344374019632  val_f1_score: 0.9744754772496922 val_specificity: 0.9994537433953523
>>>Epoch: 27 / 50 
  train_loss: 0.0013291739737588512  train_accuracy:99.04%  train_precision: 0.9579594356418727  train_recall: 0.9955278694621263  train_f1_score: 0.9763824039355422 train_specificity: 0.989132119109567 
  val_loss: 8.358275470032521e-05  val_accuracy:99.95%  val_precision: 0.9619744299458968  val_recall: 0.994820418455599  val_f1_score: 0.9781217537802375 val_specificity: 0.9995330517616565
>>>Epoch: 28 / 50 
  train_loss: 0.001294570365948425  train_accuracy:99.10%  train_precision: 0.9606104925034233  train_recall: 0.9954070010692111  train_f1_score: 0.9776992406168309 train_specificity: 0.989846776525005 
  val_loss: 7.712902404454344e-05  val_accuracy:99.95%  val_precision: 0.9661465220840408  val_recall: 0.9958427042867174  val_f1_score: 0.9807698756620785 val_specificity: 0.9995856542495115
>>>Epoch: 29 / 50 
  train_loss: 0.0011963272080851076  train_accuracy:99.18%  train_precision: 0.9642139956235448  train_recall: 0.9955371670308122  train_f1_score: 0.9796252579583354 train_specificity: 0.990808904307601 
  val_loss: 7.769954894507279e-05  val_accuracy:99.96%  val_precision: 0.9680667815025197  val_recall: 0.9958427042867174  val_f1_score: 0.9817583224751408 val_specificity: 0.9996099323208291
>>>Epoch: 30 / 50 
  train_loss: 0.0012276420863607622  train_accuracy:99.14%  train_precision: 0.9623416299757304  train_recall: 0.9957603086792711  train_f1_score: 0.9787657926414011 train_specificity: 0.9903070251517757 
  val_loss: 7.625678382145342e-05  val_accuracy:99.95%  val_precision: 0.9656927551559382  val_recall: 0.9956382471204936  val_f1_score: 0.9804368975907187 val_specificity: 0.999579989366204
>>>Epoch: 31 / 50 
  train_loss: 0.0012505265941131273  train_accuracy:99.15%  train_precision: 0.963376885145584  train_recall: 0.9954162986378969  train_f1_score: 0.9791345616826047 train_specificity: 0.9905868748193096 
  val_loss: 7.843468310356578e-05  val_accuracy:99.95%  val_precision: 0.964087668338991  val_recall: 0.9952974851767876  val_f1_score: 0.9794440154619671 val_specificity: 0.999559757640106
>>>Epoch: 32 / 50 
  train_loss: 0.001067623246594815  train_accuracy:99.24%  train_precision: 0.9664465851282519  train_recall: 0.9962158895448747  train_f1_score: 0.9811054691621837 train_specificity: 0.9913963573287055 
  val_loss: 6.845907322792886e-05  val_accuracy:99.96%  val_precision: 0.973091781004331  val_recall: 0.9957063995092349  val_f1_score: 0.9842692082445679 val_specificity: 0.9996730553062549
>>>Epoch: 33 / 50 
  train_loss: 0.0010322667257129745  train_accuracy:99.24%  train_precision: 0.9669666146195206  train_recall: 0.996113616289331  train_f1_score: 0.9813237336541276 train_specificity: 0.9915351257588876 
  val_loss: 5.445458071738428e-05  val_accuracy:99.96%  val_precision: 0.97249352202505  val_recall: 0.9975465140052479  val_f1_score: 0.9848607181112378 val_specificity: 0.9996649626158157
>>>Epoch: 34 / 50 
  train_loss: 0.0010097305173709676  train_accuracy:99.33%  train_precision: 0.9708856630239677  train_recall: 0.9961879968388173  train_f1_score: 0.9833740983376832 train_specificity: 0.9925689505637445 
  val_loss: 6.386381173769552e-05  val_accuracy:99.96%  val_precision: 0.9721926556678437  val_recall: 0.9959790090641998  val_f1_score: 0.9839420967900252 val_specificity: 0.9996617255396401
>>>Epoch: 35 / 50 
  train_loss: 0.0009507944044247682  train_accuracy:99.34%  train_precision: 0.9710449546105113  train_recall: 0.9965320068801915  train_f1_score: 0.9836234066940289 train_specificity: 0.9926082682856294 
  val_loss: 5.733116852102209e-05  val_accuracy:99.97%  val_precision: 0.9775431092099333  val_recall: 0.9967968377290944  val_f1_score: 0.9870760919582228 val_specificity: 0.9997280856012416
>>>Epoch: 36 / 50 
  train_loss: 0.0009593868471614352  train_accuracy:99.34%  train_precision: 0.9709711614253398  train_recall: 0.9964111384872762  train_f1_score: 0.9835266688587618 train_specificity: 0.9925897658282717 
  val_loss: 5.485315616624801e-05  val_accuracy:99.97%  val_precision: 0.9747535305088613  val_recall: 0.997273904450283  val_f1_score: 0.9858851266686024 val_specificity: 0.999693287032353
>>>Epoch: 37 / 50 
  train_loss: 0.0008725850004337559  train_accuracy:99.36%  train_precision: 0.9717473668944675  train_recall: 0.9967830412347078  train_f1_score: 0.9841060023181238 train_specificity: 0.9927909800520359 
  val_loss: 5.522427713649053e-05  val_accuracy:99.97%  val_precision: 0.9770176376268722  val_recall: 0.996660532951612  val_f1_score: 0.986741337511521 val_specificity: 0.9997216114488903
>>>Epoch: 38 / 50 
  train_loss: 0.000881210108390143  train_accuracy:99.39%  train_precision: 0.9736220615485142  train_recall: 0.9965877922923062  train_f1_score: 0.9849710765192689 train_specificity: 0.9932836079791825 
  val_loss: 5.23889339389064e-05  val_accuracy:99.97%  val_precision: 0.9740328916704858  val_recall: 0.9970012948953181  val_f1_score: 0.9853832677203975 val_specificity: 0.9996843850728698
>>>Epoch: 39 / 50 
  train_loss: 0.0008001644825788171  train_accuracy:99.45%  train_precision: 0.9758996668911574  train_recall: 0.9969410999023662  train_f1_score: 0.986308173662648 train_specificity: 0.9938756866146262 
  val_loss: 5.776389662194981e-05  val_accuracy:99.97%  val_precision: 0.9752600693517621  val_recall: 0.9967286853403532  val_f1_score: 0.9858775147516021 val_specificity: 0.9996997611847044
>>>Epoch: 40 / 50 
  train_loss: 0.0008165099241928132  train_accuracy:99.40%  train_precision: 0.9737126460786807  train_recall: 0.9970154804518525  train_f1_score: 0.9852262908214258 train_specificity: 0.9933044232437098 
  val_loss: 5.149143432177044e-05  val_accuracy:99.97%  val_precision: 0.9797736253431799  val_recall: 0.9970012948953181  val_f1_score: 0.9883123897175092 val_specificity: 0.9997556007487349
>>>Epoch: 41 / 50 
  train_loss: 0.0007501653156790074  train_accuracy:99.47%  train_precision: 0.9767234313814682  train_recall: 0.9972014318255683  train_f1_score: 0.9868562091014065 train_specificity: 0.9940884648742389 
  val_loss: 4.899210913571696e-05  val_accuracy:99.97%  val_precision: 0.9778074866309506  val_recall: 0.9969331425065768  val_f1_score: 0.9872776966619279 val_specificity: 0.9997313226774173
>>>Epoch: 42 / 50 
  train_loss: 0.0008493437474387774  train_accuracy:99.43%  train_precision: 0.9751034702324012  train_recall: 0.9966807679791642  train_f1_score: 0.9857740580774567 train_specificity: 0.9936698467765227 
  val_loss: 4.613015129229581e-05  val_accuracy:99.97%  val_precision: 0.9780168381664454  val_recall: 0.9975465140052479  val_f1_score: 0.9876851440730109 val_specificity: 0.999733750484549
>>>Epoch: 43 / 50 
  train_loss: 0.000754456642787486  train_accuracy:99.48%  train_precision: 0.9768680843313057  train_recall: 0.997303705081112  train_f1_score: 0.9869801246380643 train_specificity: 0.9941254697889541 
  val_loss: 4.857167820862402e-05  val_accuracy:99.97%  val_precision: 0.9790008693906922  val_recall: 0.9976828187827304  val_f1_score: 0.9882535605612078 val_specificity: 0.9997458895202079
>>>Epoch: 44 / 50 
  train_loss: 0.0007936085644553688  train_accuracy:99.48%  train_precision: 0.9772342169991711  train_recall: 0.9973594904932267  train_f1_score: 0.987194293759792 train_specificity: 0.9942202948829119 
  val_loss: 3.9483167771240214e-05  val_accuracy:99.98%  val_precision: 0.9834755155504142  val_recall: 0.9978191235602127  val_f1_score: 0.9905953986880512 val_specificity: 0.9998009198151946
>>>Epoch: 45 / 50 
  train_loss: 0.0007190393396790743  train_accuracy:99.53%  train_precision: 0.9793644996347609  train_recall: 0.997257217237683  train_f1_score: 0.9882298739673818 train_specificity: 0.9947730557964707 
  val_loss: 4.731176759649631e-05  val_accuracy:99.97%  val_precision: 0.9817461915307039  val_recall: 0.9970012948953181  val_f1_score: 0.9893149382975552 val_specificity: 0.9997798788200526
>>>Epoch: 46 / 50 
  train_loss: 0.0006567115080018925  train_accuracy:99.55%  train_precision: 0.9803070455999179  train_recall: 0.9973966807679698  train_f1_score: 0.9887780256308667 train_specificity: 0.9950159005492895 
  val_loss: 3.984601472827556e-05  val_accuracy:99.98%  val_precision: 0.9843266514192799  val_recall: 0.997273904450283  val_f1_score: 0.9907579804742593 val_specificity: 0.9998114403127656
>>>Epoch: 47 / 50 
  train_loss: 0.0006802735327136228  train_accuracy:99.56%  train_precision: 0.9809704085738232  train_recall: 0.9973966807679698  train_f1_score: 0.9891153509575354 train_specificity: 0.9951870482798474 
  val_loss: 4.4601765650965225e-05  val_accuracy:99.97%  val_precision: 0.9801794562742078  val_recall: 0.9976146663939891  val_f1_score: 0.9888202109364567 val_specificity: 0.9997604563629985
>>>Epoch: 48 / 50 
  train_loss: 0.0006171220756881976  train_accuracy:99.58%  train_precision: 0.9815726389371696  train_recall: 0.9974431686113988  train_f1_score: 0.9894442671701529 train_specificity: 0.9953420063602174 
  val_loss: 4.116739178293618e-05  val_accuracy:99.98%  val_precision: 0.9818303721085496  val_recall: 0.9980235807264364  val_f1_score: 0.9898607538598421 val_specificity: 0.9997806880890965
>>>Epoch: 49 / 50 
  train_loss: 0.0005868157427464984  train_accuracy:99.60%  train_precision: 0.98234900987832  train_recall: 0.9976384175538003  train_f1_score: 0.9899346810263325 train_specificity: 0.9955409077768118 
  val_loss: 3.699294296656038e-05  val_accuracy:99.98%  val_precision: 0.9851298613914019  val_recall: 0.9978191235602127  val_f1_score: 0.9914338914925045 val_specificity: 0.9998211515412926
>>>Epoch: 50 / 50 
  train_loss: 0.0006411788333696377  train_accuracy:99.58%  train_precision: 0.9815746619581635  train_recall: 0.9975547394356282  train_f1_score: 0.9895001862555949 train_specificity: 0.9953420063602174 
  val_loss: 3.3506208041176904e-05  val_accuracy:99.98%  val_precision: 0.9867880013480966  val_recall: 0.9976828187827304  val_f1_score: 0.9922055030921939 val_specificity: 0.9998413832673907
Model saved in file: ./results/xin_46/log/521model.ckpt
F:\wei_loss\datame\train_focal_loss.py:267: UserWarning: The following kwargs were not used by contour: 'aspect'
  h3 = plt.contourf(A[13200,:,:,0],cmap = plt.cm.GnBu,norm = norm,aspect='auto')#A[13200,:,:,0]